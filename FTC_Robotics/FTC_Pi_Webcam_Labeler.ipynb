{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3fcce8",
   "metadata": {},
   "source": [
    "\n",
    "# Raspberry Pi Webcam Capture & Labeling (Logitech C270, 720p)\n",
    "\n",
    "This notebook gives you an in-notebook interface to:\n",
    "- **Preview** your Logitech C270 camera (1280×720)\n",
    "- **Capture** images with a selected **class label**\n",
    "- **Review & relabel** captured images\n",
    "\n",
    "It stores images under `datasets/raw/<label>/IMG_...jpg` and writes a `datasets/raw/manifest.csv` with columns: `filepath,label,timestamp`.\n",
    "\n",
    "> If you haven't already, install dependencies on your Pi:\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install -y python3-opencv\n",
    "pip install ipywidgets\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b719d56",
   "metadata": {},
   "source": [
    "## 0) Imports & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be439c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, csv, time, threading, io, glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Root dataset folder\n",
    "DATA_ROOT = Path('datasets/raw')\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MANIFEST = DATA_ROOT / 'manifest.csv'\n",
    "if not MANIFEST.exists():\n",
    "    with open(MANIFEST, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['filepath','label','timestamp'])\n",
    "\n",
    "print('Dataset root:', DATA_ROOT.resolve())\n",
    "print('Manifest:', MANIFEST.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c7661",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Live Camera Preview + Capture\n",
    "- Choose a **label** from the dropdown (edit/add to the list as you wish).\n",
    "- Press **Start Preview** to see the live feed.\n",
    "- Press **Capture** to save a frame to the selected label folder.\n",
    "- Press **Stop Preview** to release the camera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- User-configurable defaults ---\n",
    "DEFAULT_LABELS = ['yellow', 'purple', 'background']  # edit as needed\n",
    "CAMERA_INDEX = 0\n",
    "FRAME_WIDTH = 1280\n",
    "FRAME_HEIGHT = 720\n",
    "JPEG_QUALITY = 90\n",
    "# ----------------------------------\n",
    "\n",
    "# Widgets\n",
    "label_dd = widgets.Dropdown(options=DEFAULT_LABELS, value=DEFAULT_LABELS[0], description='Label:', layout=widgets.Layout(width='250px'))\n",
    "new_label_txt = widgets.Text(placeholder='Add new label', description='New label:')\n",
    "add_label_btn = widgets.Button(description='Add Label', button_style='')\n",
    "start_btn = widgets.Button(description='Start Preview', button_style='success')\n",
    "stop_btn = widgets.Button(description='Stop Preview', button_style='warning', disabled=True)\n",
    "capture_btn = widgets.Button(description='Capture', button_style='primary', disabled=True)\n",
    "status_out = widgets.Output(layout={'border': '1px solid #ccc'})\n",
    "image_widget = widgets.Image(format='jpg', width=640, height=360)\n",
    "\n",
    "controls = widgets.HBox([label_dd, new_label_txt, add_label_btn, start_btn, stop_btn, capture_btn])\n",
    "ui = widgets.VBox([controls, image_widget, status_out])\n",
    "\n",
    "display(ui)\n",
    "\n",
    "# State\n",
    "cap = None\n",
    "preview_running = False\n",
    "\n",
    "def log(msg):\n",
    "    with status_out:\n",
    "        print(msg)\n",
    "\n",
    "def add_label_clicked(_):\n",
    "    txt = new_label_txt.value.strip()\n",
    "    if txt and txt not in label_dd.options:\n",
    "        label_dd.options = list(label_dd.options) + [txt]\n",
    "        label_dd.value = txt\n",
    "        new_label_txt.value = ''\n",
    "        log(f'[INFO] Added label: {txt}')\n",
    "    elif txt:\n",
    "        log(f'[WARN] Label \"{txt}\" already exists.')\n",
    "\n",
    "add_label_btn.on_click(add_label_clicked)\n",
    "\n",
    "def start_preview(_):\n",
    "    global cap, preview_running\n",
    "    if preview_running:\n",
    "        log('[WARN] Preview already running.')\n",
    "        return\n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "    if not cap.isOpened():\n",
    "        log('[ERROR] Could not open camera index %d' % CAMERA_INDEX)\n",
    "        return\n",
    "    preview_running = True\n",
    "    start_btn.disabled = True\n",
    "    stop_btn.disabled = False\n",
    "    capture_btn.disabled = False\n",
    "\n",
    "    def loop():\n",
    "        global preview_running\n",
    "        while preview_running:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                log('[WARN] Failed to read frame.')\n",
    "                time.sleep(0.05)\n",
    "                continue\n",
    "            overlay = frame.copy()\n",
    "            cv2.putText(overlay, f'label: {label_dd.value}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), 2)\n",
    "            cv2.putText(overlay, f'{FRAME_WIDTH}x{FRAME_HEIGHT}', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "            # Encode to JPEG for display\n",
    "            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY]\n",
    "            ret, jpg = cv2.imencode('.jpg', overlay, encode_param)\n",
    "            if ret:\n",
    "                image_widget.value = jpg.tobytes()\n",
    "            time.sleep(0.03)  # ~30 FPS ceiling\n",
    "\n",
    "    threading.Thread(target=loop, daemon=True).start()\n",
    "    log('[INFO] Preview started.')\n",
    "\n",
    "def stop_preview(_):\n",
    "    global cap, preview_running\n",
    "    preview_running = False\n",
    "    start_btn.disabled = False\n",
    "    stop_btn.disabled = True\n",
    "    capture_btn.disabled = True\n",
    "    if cap is not None:\n",
    "        cap.release()\n",
    "        cap = None\n",
    "    log('[INFO] Preview stopped.')\n",
    "\n",
    "def capture_frame(_):\n",
    "    global cap\n",
    "    if cap is None:\n",
    "        log('[ERROR] Camera not started.')\n",
    "        return\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        log('[ERROR] Could not capture frame.')\n",
    "        return\n",
    "    label = label_dd.value\n",
    "    label_dir = DATA_ROOT / label\n",
    "    label_dir.mkdir(parents=True, exist_ok=True)\n",
    "    ts = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]  # ms\n",
    "    fname = f'IMG_{ts}.jpg'\n",
    "    fpath = label_dir / fname\n",
    "    cv2.imwrite(str(fpath), frame, [int(cv2.IMWRITE_JPEG_QUALITY), JPEG_QUALITY])\n",
    "    with open(MANIFEST, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([str(fpath), label, ts])\n",
    "    log(f'[SAVED] {fpath}')\n",
    "\n",
    "start_btn.on_click(start_preview)\n",
    "stop_btn.on_click(stop_preview)\n",
    "capture_btn.on_click(capture_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182b7e7",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Review & Relabel Images\n",
    "- Use **Load List** to scan your dataset.\n",
    "- Navigate with **Prev/Next**.\n",
    "- Change the **label dropdown** and click **Save Label** to update the manifest **and** move the file to the label’s folder.\n",
    "- Use **Delete Image** to remove a bad capture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d8d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Widgets for review UI\n",
    "load_btn = widgets.Button(description='Load List', button_style='success')\n",
    "prev_btn = widgets.Button(description='Prev', button_style='')\n",
    "next_btn = widgets.Button(description='Next', button_style='')\n",
    "save_label_btn = widgets.Button(description='Save Label', button_style='primary')\n",
    "delete_btn = widgets.Button(description='Delete Image', button_style='danger')\n",
    "review_label_dd = widgets.Dropdown(options=list(label_dd.options), description='Label:', layout=widgets.Layout(width='250px'))\n",
    "idx_label = widgets.Label('Index: - / -')\n",
    "review_img = widgets.Image(format='jpg', width=640, height=360)\n",
    "review_out = widgets.Output(layout={'border': '1px solid #ccc'})\n",
    "\n",
    "review_controls = widgets.HBox([load_btn, prev_btn, next_btn, save_label_btn, delete_btn])\n",
    "review_ui = widgets.VBox([review_controls, idx_label, review_label_dd, review_img, review_out])\n",
    "display(review_ui)\n",
    "\n",
    "file_list = []\n",
    "cur_idx = -1\n",
    "\n",
    "def review_log(msg):\n",
    "    with review_out:\n",
    "        print(msg)\n",
    "\n",
    "def read_manifest():\n",
    "    rows = []\n",
    "    if MANIFEST.exists():\n",
    "        with open(MANIFEST, 'r', newline='') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for r in reader:\n",
    "                rows.append(r)\n",
    "    return rows\n",
    "\n",
    "def write_manifest(rows):\n",
    "    with open(MANIFEST, 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['filepath','label','timestamp'])\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "\n",
    "def load_list(_):\n",
    "    global file_list, cur_idx\n",
    "    rows = read_manifest()\n",
    "    file_list = rows  # list of dicts with filepath/label/timestamp\n",
    "    cur_idx = 0 if file_list else -1\n",
    "    review_log(f'[INFO] Loaded {len(file_list)} records from manifest.')\n",
    "    show_current()\n",
    "\n",
    "def show_current():\n",
    "    global cur_idx\n",
    "    if cur_idx < 0 or cur_idx >= len(file_list):\n",
    "        idx_label.value = 'Index: - / -'\n",
    "        review_img.value = b''\n",
    "        return\n",
    "    idx_label.value = f'Index: {cur_idx+1} / {len(file_list)}'\n",
    "    rec = file_list[cur_idx]\n",
    "    fpath = rec['filepath']\n",
    "    review_label_dd.value = rec['label'] if rec['label'] in review_label_dd.options else review_label_dd.options[0]\n",
    "    if os.path.exists(fpath):\n",
    "        img = cv2.imread(fpath)\n",
    "        # Resize preview to fit widget if needed\n",
    "        if img is not None:\n",
    "            preview = cv2.resize(img, (640, 360)) if img.shape[1] != 640 else img\n",
    "            ret, jpg = cv2.imencode('.jpg', preview, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "            if ret:\n",
    "                review_img.value = jpg.tobytes()\n",
    "    else:\n",
    "        review_log(f'[WARN] File missing: {fpath}')\n",
    "        review_img.value = b''\n",
    "\n",
    "def prev_rec(_):\n",
    "    global cur_idx\n",
    "    if cur_idx > 0:\n",
    "        cur_idx -= 1\n",
    "        show_current()\n",
    "\n",
    "def next_rec(_):\n",
    "    global cur_idx\n",
    "    if cur_idx < len(file_list)-1:\n",
    "        cur_idx += 1\n",
    "        show_current()\n",
    "\n",
    "def save_label(_):\n",
    "    global file_list, cur_idx\n",
    "    if cur_idx < 0: return\n",
    "    new_label = review_label_dd.value\n",
    "    rec = file_list[cur_idx]\n",
    "    old_path = Path(rec['filepath'])\n",
    "    ts = rec['timestamp']\n",
    "    # Move file to new label folder if changed\n",
    "    new_dir = DATA_ROOT / new_label\n",
    "    new_dir.mkdir(parents=True, exist_ok=True)\n",
    "    new_path = new_dir / Path(old_path.name)\n",
    "    if old_path.exists() and str(new_path) != str(old_path):\n",
    "        try:\n",
    "            old_path.replace(new_path)  # move\n",
    "        except Exception as e:\n",
    "            review_log(f'[ERROR] Could not move file: {e}')\n",
    "            return\n",
    "    # Update manifest entry\n",
    "    rec['filepath'] = str(new_path)\n",
    "    rec['label'] = new_label\n",
    "    # Write back manifest\n",
    "    write_manifest(file_list)\n",
    "    review_log(f'[SAVED] Updated label to \"{new_label}\" for {new_path}')\n",
    "    show_current()\n",
    "\n",
    "def delete_image(_):\n",
    "    global file_list, cur_idx\n",
    "    if cur_idx < 0: return\n",
    "    rec = file_list[cur_idx]\n",
    "    fpath = Path(rec['filepath'])\n",
    "    # Remove file\n",
    "    if fpath.exists():\n",
    "        try:\n",
    "            fpath.unlink()\n",
    "        except Exception as e:\n",
    "            review_log(f'[ERROR] Could not delete file: {e}')\n",
    "            return\n",
    "    # Remove from list and rewrite manifest\n",
    "    del file_list[cur_idx]\n",
    "    write_manifest(file_list)\n",
    "    review_log(f'[DELETED] {fpath}')\n",
    "    # Adjust index and show\n",
    "    if cur_idx >= len(file_list):\n",
    "        cur_idx = len(file_list)-1\n",
    "    show_current()\n",
    "\n",
    "load_btn.on_click(load_list)\n",
    "prev_btn.on_click(prev_rec)\n",
    "next_btn.on_click(next_rec)\n",
    "save_label_btn.on_click(save_label)\n",
    "delete_btn.on_click(delete_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe2b5fc",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Export Summary (Optional)\n",
    "Quick check: how many images per label?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9abae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(MANIFEST)\n",
    "summary = df['label'].value_counts().rename_axis('label').reset_index(name='count')\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cb1bd1",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 4) Bounding Box Labeler (YOLO format)\n",
    "\n",
    "Use this section to **draw bounding boxes** on your captured images for **object detection**.  \n",
    "It saves YOLO-format `.txt` files in `datasets/bbox_labels/` and a `datasets/labels.txt` file listing class names.\n",
    "\n",
    "**Controls**\n",
    "- Mouse: click–drag to draw a new box; drag corners later to adjust (basic edit supported)\n",
    "- Keys: `1..9` choose class • `u` undo • `d` delete box under cursor • `n/p` next/prev image • `s` save • `q` quit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddbf27",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 Configure Classes\n",
    "Edit `CLASS_NAMES` so indices map to class IDs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import cv2, json\n",
    "import numpy as np\n",
    "\n",
    "# Folder with images saved by this notebook:\n",
    "IMG_ROOT = Path('datasets/raw')\n",
    "\n",
    "# YOLO label output folder:\n",
    "LBL_ROOT = Path('datasets/bbox_labels')\n",
    "LBL_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Class list: index = class id (0-based)\n",
    "CLASS_NAMES = ['yellow', 'purple', 'background_obj']  # <-- edit as needed\n",
    "(Path('datasets') / 'labels.txt').write_text('\\n'.join(CLASS_NAMES))\n",
    "\n",
    "IMG_EXTS = ('.jpg', '.jpeg', '.png')\n",
    "def sorted_images():\n",
    "    imgs = []\n",
    "    for p in IMG_ROOT.rglob('*'):\n",
    "        if p.suffix.lower() in IMG_EXTS:\n",
    "            imgs.append(p)\n",
    "    return sorted(imgs)\n",
    "\n",
    "IMAGES = sorted_images()\n",
    "print('Found images:', len(IMAGES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b1bc0",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 Launch the Annotator\n",
    "This opens a native OpenCV window. Close with `q`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ccec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yolo_save(lbl_path, boxes, cls_ids, W, H):\n",
    "    with open(lbl_path, 'w') as f:\n",
    "        for (x1,y1,x2,y2), c in zip(boxes, cls_ids):\n",
    "            x1, y1 = max(0,x1), max(0,y1)\n",
    "            x2, y2 = min(W-1,x2), min(H-1,y2)\n",
    "            w, h = x2-x1, y2-y1\n",
    "            xc, yc = x1 + w/2.0, y1 + h/2.0\n",
    "            f.write(f\"{c} {xc/W:.6f} {yc/H:.6f} {w/W:.6f} {h/H:.6f}\\n\")\n",
    "\n",
    "def yolo_load(lbl_path, W, H):\n",
    "    boxes, cls_ids = [], []\n",
    "    if not lbl_path.exists(): return boxes, cls_ids\n",
    "    for line in lbl_path.read_text().strip().splitlines():\n",
    "        parts = line.split()\n",
    "        if len(parts) != 5: continue\n",
    "        c = int(parts[0]); xc=float(parts[1])*W; yc=float(parts[2])*H; w=float(parts[3])*W; h=float(parts[4])*H\n",
    "        x1=int(xc-w/2); y1=int(yc-h/2); x2=int(xc+w/2); y2=int(yc+h/2)\n",
    "        boxes.append([x1,y1,x2,y2]); cls_ids.append(c)\n",
    "    return boxes, cls_ids\n",
    "\n",
    "def hit_test(pt, boxes, tol=6):\n",
    "    x,y = pt\n",
    "    for i,(x1,y1,x2,y2) in enumerate(boxes):\n",
    "        if x1-tol <= x <= x2+tol and y1-tol <= y <= y2+tol:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def clamp_box(x1,y1,x2,y2,W,H):\n",
    "    x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "    y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "    if x2 < x1: x1,x2 = x2,x1\n",
    "    if y2 < y1: y1,y2 = y2,y1\n",
    "    return [x1,y1,x2,y2]\n",
    "\n",
    "def draw_overlay(img, boxes, cls_ids, cur_class_id, hover_idx):\n",
    "    out = img.copy()\n",
    "    cv2.putText(out, f\"Class: {cur_class_id} ({CLASS_NAMES[cur_class_id]})\", (10,25),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.putText(out, \"1-9 class | u undo | d delete | n/p next/prev | s save | q quit\", (10,55),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "    for i,(x1,y1,x2,y2) in enumerate(boxes):\n",
    "        color = (0,255,0) if i != hover_idx else (0,0,255)\n",
    "        cv2.rectangle(out,(x1,y1),(x2,y2),color,2)\n",
    "        name = CLASS_NAMES[cls_ids[i]] if 0 <= cls_ids[i] < len(CLASS_NAMES) else str(cls_ids[i])\n",
    "        cv2.putText(out, name, (x1, max(0,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return out\n",
    "\n",
    "def annotate_images():\n",
    "    IMGS = IMAGES\n",
    "    if not IMGS:\n",
    "        print('[INFO] No images found under', IMG_ROOT.resolve())\n",
    "        return\n",
    "    idx = 0\n",
    "    cur_class = 0\n",
    "    win = 'BBox Labeler'\n",
    "    cv2.namedWindow(win, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    boxes, cls_ids = [], []\n",
    "    drawing = False\n",
    "    start_pt = None\n",
    "    hover_idx = -1\n",
    "\n",
    "    def load_current():\n",
    "        nonlocal img, H, W, boxes, cls_ids\n",
    "        img_path = IMGS[idx]\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print('[WARN] Could not read', img_path)\n",
    "            boxes, cls_ids = [], []\n",
    "            return\n",
    "        H, W = img.shape[:2]\n",
    "        lbl_path = LBL_ROOT / (img_path.stem + '.txt')\n",
    "        boxes, cls_ids = yolo_load(lbl_path, W, H)\n",
    "\n",
    "    def on_mouse(evt,x,y,flags,param):\n",
    "        nonlocal drawing, start_pt, hover_idx, boxes, cls_ids\n",
    "        if evt == cv2.EVENT_MOUSEMOVE:\n",
    "            hover_idx = hit_test((x,y), boxes)\n",
    "        elif evt == cv2.EVENT_LBUTTONDOWN:\n",
    "            drawing = True; start_pt = (x,y)\n",
    "        elif evt == cv2.EVENT_LBUTTONUP:\n",
    "            if drawing and start_pt is not None:\n",
    "                b = clamp_box(start_pt[0], start_pt[1], x, y, W, H)\n",
    "                if abs(b[2]-b[0])>5 and abs(b[3]-b[1])>5:\n",
    "                    boxes.append(b); cls_ids.append(cur_class)\n",
    "            drawing = False; start_pt=None\n",
    "\n",
    "    load_current()\n",
    "    cv2.setMouseCallback(win, on_mouse)\n",
    "\n",
    "    while True:\n",
    "        disp = draw_overlay(img, boxes, cls_ids, cur_class, hover_idx)\n",
    "        cv2.imshow(win, disp)\n",
    "        k = cv2.waitKey(20) & 0xFF\n",
    "\n",
    "        if k in [ord(str(x)) for x in range(10)]:  # 1..9 select classes 0..8\n",
    "            num = int(chr(k))\n",
    "            if 1 <= num <= min(9, len(CLASS_NAMES)):\n",
    "                cur_class = num-1\n",
    "        elif k == ord('u'):\n",
    "            if boxes: boxes.pop(); cls_ids.pop()\n",
    "        elif k == ord('d'):\n",
    "            if 0 <= hover_idx < len(boxes):\n",
    "                boxes.pop(hover_idx); cls_ids.pop(hover_idx); hover_idx=-1\n",
    "        elif k == ord('s'):\n",
    "            img_path = IMGS[idx]\n",
    "            yolo_save(LBL_ROOT / (img_path.stem + '.txt'), boxes, cls_ids, W, H)\n",
    "            print('[SAVED]', LBL_ROOT / (img_path.stem + '.txt'))\n",
    "        elif k == ord('n'):\n",
    "            idx = min(idx+1, len(IMGS)-1); load_current()\n",
    "        elif k == ord('p'):\n",
    "            idx = max(0, idx-1); load_current()\n",
    "        elif k == ord('q') or k == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the annotator with:\n",
    "# annotate_images()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7258b",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 (Optional) Export COCO JSON\n",
    "Convert YOLO labels to a `datasets/coco_annotations.json` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "def yolo_to_coco():\n",
    "    images = []\n",
    "    annotations = []\n",
    "    categories = [{\"id\": i, \"name\": n} for i, n in enumerate(CLASS_NAMES)]\n",
    "    ann_id = 1\n",
    "    for img_id, img_path in enumerate(IMAGES, start=1):\n",
    "        if not img_path.exists(): \n",
    "            continue\n",
    "        with Image.open(img_path) as im:\n",
    "            W, H = im.size\n",
    "        images.append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": str(img_path.relative_to(IMG_ROOT.parent)),\n",
    "            \"width\": W, \"height\": H\n",
    "        })\n",
    "        lbl_path = LBL_ROOT / (img_path.stem + '.txt')\n",
    "        if not lbl_path.exists():\n",
    "            continue\n",
    "        for line in lbl_path.read_text().splitlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5: \n",
    "                continue\n",
    "            c = int(parts[0])\n",
    "            xc = float(parts[1]) * W\n",
    "            yc = float(parts[2]) * H\n",
    "            w  = float(parts[3]) * W\n",
    "            h  = float(parts[4]) * H\n",
    "            x1 = xc - w/2\n",
    "            y1 = yc - h/2\n",
    "            annotations.append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": c,\n",
    "                \"bbox\": [x1, y1, w, h],\n",
    "                \"area\": float(w*h),\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            ann_id += 1\n",
    "    coco = {\"images\": images, \"annotations\": annotations, \"categories\": categories}\n",
    "    out = Path('datasets/coco_annotations.json')\n",
    "    out.write_text(json.dumps(coco, indent=2))\n",
    "    return out\n",
    "\n",
    "# Generate file with:\n",
    "# yolo_to_coco()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058d6cb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 5) Preprocess Images for FTC-ML (300×300)\n",
    "\n",
    "FTC-ML resizes all inputs to **300×300** during training.  \n",
    "This step makes sure your dataset matches that expectation.\n",
    "\n",
    "- Creates a `datasets/processed_300/` folder\n",
    "- Resizes each image from `datasets/raw/` (letterboxing to keep aspect ratio)\n",
    "- Copies YOLO labels if available (adjusted to new size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import cv2, shutil\n",
    "\n",
    "RAW_DIR = Path('datasets/raw')\n",
    "PROC_DIR = Path('datasets/processed_300')\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET = 300\n",
    "\n",
    "def resize_and_pad(img, size=300):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = size / max(h, w)\n",
    "    new_w, new_h = int(w*scale), int(h*scale)\n",
    "    resized = cv2.resize(img, (new_w, new_h))\n",
    "    # pad to square\n",
    "    delta_w, delta_h = size - new_w, size - new_h\n",
    "    top, bottom = delta_h//2, delta_h - (delta_h//2)\n",
    "    left, right = delta_w//2, delta_w - (delta_w//2)\n",
    "    color = [0,0,0]\n",
    "    new_img = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return new_img, scale, left, top\n",
    "\n",
    "out_manifest = PROC_DIR / 'manifest.csv'\n",
    "with open(out_manifest, 'w') as mf:\n",
    "    mf.write('filepath,label,timestamp\\n')\n",
    "\n",
    "count = 0\n",
    "for img_path in RAW_DIR.rglob('*.jpg'):\n",
    "    rel = img_path.relative_to(RAW_DIR)\n",
    "    out_path = PROC_DIR / rel\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None: continue\n",
    "    new_img, scale, dx, dy = resize_and_pad(img, TARGET)\n",
    "    cv2.imwrite(str(out_path), new_img)\n",
    "    count += 1\n",
    "print(f'[DONE] Processed {count} images -> {PROC_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd68b2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# 5) FTC‑ML 300×300 Export (letterboxed)\n",
    "\n",
    "FTC‑ML training resizes inputs to **300×300**. Use these helpers to **export copies** of your dataset that are already letterboxed to 300×300 so your preview/testing matches what the toolchain sees.\n",
    "\n",
    "- **Classification export**: reads `datasets/raw/manifest.csv` and writes images to `datasets/ftcml_300/<label>/...`\n",
    "- **Detection export**: reads images under `datasets/raw/...` and YOLO labels in `datasets/bbox_labels/` and writes **images + adjusted YOLO labels** to `datasets/ftcml_300_bbox/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf556e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import cv2, csv, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RAW_ROOT = Path('datasets/raw')\n",
    "MANIFEST = RAW_ROOT / 'manifest.csv'\n",
    "\n",
    "EX_CLF_ROOT = Path('datasets/ftcml_300')\n",
    "EX_BBOX_IMG = Path('datasets/ftcml_300_bbox/images')\n",
    "EX_BBOX_LBL = Path('datasets/ftcml_300_bbox/labels')\n",
    "for p in [EX_CLF_ROOT, EX_BBOX_IMG, EX_BBOX_LBL]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def letterbox(img, size=(300,300)):\n",
    "    H, W = img.shape[:2]\n",
    "    tw, th = size[0], size[1]\n",
    "    scale = min(tw / W, th / H)\n",
    "    nw, nh = int(round(W * scale)), int(round(H * scale))\n",
    "    resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "    # Create padded canvas (black)\n",
    "    canvas = np.zeros((th, tw, 3), dtype=img.dtype)\n",
    "    x0 = (tw - nw) // 2\n",
    "    y0 = (th - nh) // 2\n",
    "    canvas[y0:y0+nh, x0:x0+nw] = resized\n",
    "    return canvas, scale, x0, y0, (W, H)\n",
    "\n",
    "def export_classification_300():\n",
    "    if not MANIFEST.exists():\n",
    "        print(\"[ERROR] No manifest at\", MANIFEST)\n",
    "        return\n",
    "    df = pd.read_csv(MANIFEST)\n",
    "    counts = {}\n",
    "    for _, row in df.iterrows():\n",
    "        fpath = Path(row['filepath'])\n",
    "        label = str(row['label'])\n",
    "        if not fpath.exists():\n",
    "            continue\n",
    "        img = cv2.imread(str(fpath))\n",
    "        if img is None: \n",
    "            continue\n",
    "        out_img, *_ = letterbox(img, (300,300))\n",
    "        out_dir = EX_CLF_ROOT / label\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = out_dir / fpath.name\n",
    "        cv2.imwrite(str(out_path), out_img, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "        counts[label] = counts.get(label, 0) + 1\n",
    "    print(\"[DONE] Exported classification set to\", EX_CLF_ROOT.resolve())\n",
    "    return counts\n",
    "\n",
    "def export_detection_300():\n",
    "    # expects YOLO labels in datasets/bbox_labels/<stem>.txt\n",
    "    IMG_EXTS = ('.jpg','.jpeg','.png')\n",
    "    raw_images = []\n",
    "    for p in RAW_ROOT.rglob('*'):\n",
    "        if p.suffix.lower() in IMG_EXTS:\n",
    "            raw_images.append(p)\n",
    "    raw_images = sorted(raw_images)\n",
    "    converted = 0\n",
    "    for img_path in raw_images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None: \n",
    "            continue\n",
    "        boxed, scale, pad_x, pad_y, (W,H) = letterbox(img, (300,300))\n",
    "        # Write image\n",
    "        out_img_path = EX_BBOX_IMG / img_path.name\n",
    "        cv2.imwrite(str(out_img_path), boxed, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "        # Read YOLO labels (if exist), transform to new coords normalized to 300x300\n",
    "        lbl_in = Path('datasets/bbox_labels') / (img_path.stem + '.txt')\n",
    "        lbl_out = EX_BBOX_LBL / (img_path.stem + '.txt')\n",
    "        if lbl_in.exists():\n",
    "            lines_out = []\n",
    "            txt = lbl_in.read_text().strip().splitlines()\n",
    "            for line in txt:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                c = int(parts[0])\n",
    "                # Denormalize from original W,H\n",
    "                xc = float(parts[1]) * W\n",
    "                yc = float(parts[2]) * H\n",
    "                w  = float(parts[3]) * W\n",
    "                h  = float(parts[4]) * H\n",
    "                # Apply scale + padding\n",
    "                xc2 = xc * scale + pad_x\n",
    "                yc2 = yc * scale + pad_y\n",
    "                w2  = w  * scale\n",
    "                h2  = h  * scale\n",
    "                # Normalize to 300x300\n",
    "                xc_n = xc2 / 300.0\n",
    "                yc_n = yc2 / 300.0\n",
    "                w_n  = w2  / 300.0\n",
    "                h_n  = h2  / 300.0\n",
    "                lines_out.append(f\"{c} {xc_n:.6f} {yc_n:.6f} {w_n:.6f} {h_n:.6f}\")\n",
    "            lbl_out.write_text(\"\\n\".join(lines_out))\n",
    "        converted += 1\n",
    "    print(f\"[DONE] Exported detection set to {EX_BBOX_IMG.parent.resolve()} with {converted} images.\")\n",
    "    return converted\n",
    "\n",
    "# Example usage:\n",
    "# export_classification_300()\n",
    "# export_detection_300()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5516fb09",
   "metadata": {},
   "source": [
    "\n",
    "### 5.1 Quick checks\n",
    "Run these to verify counts and spot-check sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7afc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export both (run as needed)\n",
    "# counts = export_classification_300()\n",
    "# total = export_detection_300()\n",
    "\n",
    "# Summaries\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def count_files(root):\n",
    "    c = Counter()\n",
    "    for p in Path(root).rglob('*.jpg'):\n",
    "        if p.parent.name not in ['images']:  # for classification buckets\n",
    "            c[p.parent.name] += 1\n",
    "    return c\n",
    "\n",
    "print(\"Classification buckets:\", count_files(EX_CLF_ROOT))\n",
    "print(\"Detection images:\", len(list(EX_BBOX_IMG.glob('*.jpg'))), \"labels:\", len(list(EX_BBOX_LBL.glob('*.txt'))))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
