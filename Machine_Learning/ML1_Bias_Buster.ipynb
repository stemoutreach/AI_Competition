{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99e9118",
   "metadata": {},
   "source": [
    "# ML Model Development Problem 1  \n",
    "**Title:** Bias Buster: Fair Loan Approval Classifier (Supervised Learning)\n",
    "\n",
    "## Scenario\n",
    "You’re building a binary classifier to **predict loan approvals**. The historical data has **embedded bias** across a protected attribute (`group` ∈ {A, B}).\n",
    "\n",
    "## Objectives\n",
    "- Data cleaning & feature engineering\n",
    "- Model selection: try at least **2 algorithms** (e.g., Logistic Regression, Random Forest)\n",
    "- Hyperparameter tuning (Grid/Random search ok)\n",
    "- Validation: **cross-validation**\n",
    "- Evaluation: **accuracy, precision, recall, F1**\n",
    "- **Ethics:** compute **Demographic Parity Difference** and **Equal Opportunity Difference**; propose a mitigation (thresholding, reweighting, or feature handling) and document trade-offs (transparency, fairness, accountability, human agency).\n",
    "\n",
    "## Deliverables\n",
    "1. Working notebook that:\n",
    "   - Trains ≥2 models and selects one final model with CV\n",
    "   - Reports metrics listed above\n",
    "   - Computes fairness metrics and applies a mitigation\n",
    "   - Provides **Permutation Feature Importance** (XAI)\n",
    "   - Produces a short **Model Card** (Markdown cell)\n",
    "2. Export the final metrics summary as a printed Python dict.\n",
    "\n",
    "## Scoring (auto-checked in notebook)\n",
    "- Accuracy ≥ 0.78 and F1 ≥ 0.78 (20 pts)\n",
    "- Equal Opportunity |Δ| ≤ 0.15 after mitigation (20 pts)\n",
    "- Demographic Parity |Δ| ≤ 0.15 after mitigation (20 pts)\n",
    "- Used CV + tuning + feature importance (20 pts)\n",
    "- Model Card covering transparency/fairness/accountability/human-in-loop (20 pts)\n",
    "\n",
    "**Total:** 100 pts\n",
    "\n",
    "## Ethics Notes\n",
    "- **Transparency**: log data cleaning steps and model choices\n",
    "- **Explainability**: include feature importance + error analysis\n",
    "- **Fairness**: measure parity and opportunity; mitigate and justify\n",
    "- **Accountability & Human Agency**: define a manual review policy for borderline cases\n",
    "\n",
    "---\n",
    "\n",
    "**How to run**\n",
    "- Open `AI_Quest_ML1_Bias_Buster.ipynb` and follow the numbered TODOs.\n",
    "- Python 3.9+ recommended. Packages: `pandas`, `numpy`, `scikit-learn`, `matplotlib`.\n",
    "- If needed, run the optional `pip install` cell inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09195c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: install packages locally (uncomment if needed)\n",
    "# !pip -q install pandas numpy scikit-learn matplotlib\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✅ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24df6c0",
   "metadata": {},
   "source": [
    "## 1) Data: Generate a synthetic, slightly biased dataset\n",
    "We simulate historical approvals with a **latent bias**: group B has slightly lower base approval rate **independent** of true risk factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c212fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "n = 4000\n",
    "income = np.random.lognormal(mean=10.5, sigma=0.5, size=n)  # ~ salaries\n",
    "dti = np.clip(np.random.normal(0.3, 0.1, size=n), 0, 1)    # debt-to-income\n",
    "credit = np.clip(np.random.normal(680, 70, size=n), 300, 850)\n",
    "years = np.clip(np.random.exponential(scale=5, size=n), 0, 40)\n",
    "age = np.clip(np.random.normal(38, 10, size=n), 18, 80)\n",
    "\n",
    "# Protected attribute\n",
    "group = np.random.choice([\"A\",\"B\"], size=n, p=[0.55, 0.45])\n",
    "\n",
    "# True approval probability (based on risk)\n",
    "base = (\n",
    "    0.35\n",
    "    + 0.00003*(income)\n",
    "    + 0.0008*(credit-600)\n",
    "    + 0.02*(years>2)\n",
    "    - 0.6*(dti>0.45)\n",
    ")\n",
    "# Inject historical bias: downward shift for group B\n",
    "bias = np.where(group==\"B\", -0.06, 0.0)\n",
    "p = np.clip(base + bias, 0.02, 0.98)\n",
    "\n",
    "approved = (np.random.rand(n) < p).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"income\": income,\n",
    "    \"dti\": dti,\n",
    "    \"credit\": credit,\n",
    "    \"years_employed\": years,\n",
    "    \"age\": age,\n",
    "    \"group\": group,\n",
    "    \"approved\": approved\n",
    "})\n",
    "\n",
    "# Add some missingness and noise\n",
    "for col in [\"income\", \"dti\", \"credit\"]:\n",
    "    idx = np.random.choice(n, size=int(0.03*n), replace=False)\n",
    "    df.loc[idx, col] = np.nan\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d347f8",
   "metadata": {},
   "source": [
    "### TODO 1 — Clean & engineer features (Transparency)\n",
    "- Impute missing values (median/most_frequent)\n",
    "- Scale numeric features (StandardScaler) — keep scaler for inference\n",
    "- One-hot encode `group` for analysis but **do not** let leakage bias the model: consider both with/without `group` as a feature and justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9684fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE: cleaning & feature engineering ===\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_cols = [\"income\",\"dti\",\"credit\",\"years_employed\",\"age\"]\n",
    "cat_cols = [\"group\"]\n",
    "\n",
    "# Example pipeline steps (you can change):\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "X_num = num_imputer.fit_transform(df[num_cols])\n",
    "\n",
    "X_num = pd.DataFrame(X_num, columns=num_cols, index=df.index)\n",
    "\n",
    "# One-hot for group (for analysis)\n",
    "X_cat = pd.get_dummies(df[cat_cols], drop_first=True)  # group_B as 1\n",
    "\n",
    "X = pd.concat([X_num, X_cat], axis=1)\n",
    "y = df[\"approved\"].values\n",
    "protected = (df[\"group\"].values)  # keep for fairness\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "X_train, X_test, y_train, y_test, prot_train, prot_test = train_test_split(\n",
    "    X_scaled, y, protected, test_size=0.25, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320a42a",
   "metadata": {},
   "source": [
    "### TODO 2 — Baseline models + Cross-Validation\n",
    "Train at least two models and perform CV + hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR CODE: model selection & tuning ===\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Logistic Regression\n",
    "logit = LogisticRegression(max_iter=200)\n",
    "param_logit = {\"C\":[0.1,1.0,3.0]}\n",
    "gs_logit = GridSearchCV(logit, param_logit, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "gs_logit.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "param_rf = {\"n_estimators\":[150,250], \"max_depth\":[None,8,12]}\n",
    "gs_rf = GridSearchCV(rf, param_rf, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "candidates = [(\"LogReg\", gs_logit), (\"RF\", gs_rf)]\n",
    "for name, gs in candidates:\n",
    "    print(name, gs.best_params_, gs.best_score_)\n",
    "\n",
    "# Pick a final model (you may change this selection logic)\n",
    "final_name, final_gs = max(candidates, key=lambda t: t[1].best_score_)\n",
    "final_model = final_gs.best_estimator_\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Selected:\", final_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e966c",
   "metadata": {},
   "source": [
    "### TODO 3 — Evaluation + Fairness metrics (before mitigation)\n",
    "Compute accuracy, precision, recall, F1. Then compute:\n",
    "- **Demographic Parity Difference** = P(ŷ=1|A) − P(ŷ=1|B)\n",
    "- **Equal Opportunity Difference** = TPR_A − TPR_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fairness_metrics(y_true, y_pred, prot):\n",
    "    A = (prot==\"A\")\n",
    "    B = (prot==\"B\")\n",
    "    # Demographic parity\n",
    "    pA = y_pred[A].mean() if A.any() else np.nan\n",
    "    pB = y_pred[B].mean() if B.any() else np.nan\n",
    "    dp = pA - pB\n",
    "    # Equal opportunity (TPR)\n",
    "    def tpr(mask):\n",
    "        if (y_true[mask]==1).sum()==0: return np.nan\n",
    "        return ((y_pred[mask]==1)&(y_true[mask]==1)).sum() / (y_true[mask]==1).sum()\n",
    "    tprA = tpr(A)\n",
    "    tprB = tpr(B)\n",
    "    eod = tprA - tprB\n",
    "    return {\"demographic_parity_diff\": dp, \"equal_opportunity_diff\": eod}\n",
    "\n",
    "yhat_proba = final_model.predict_proba(X_test)[:,1] if hasattr(final_model,\"predict_proba\") else final_model.predict(X_test)\n",
    "threshold = 0.5\n",
    "yhat = (yhat_proba >= threshold).astype(int)\n",
    "\n",
    "metrics_before = {\n",
    "    \"accuracy\": accuracy_score(y_test, yhat),\n",
    "    \"precision\": precision_score(y_test, yhat),\n",
    "    \"recall\": recall_score(y_test, yhat),\n",
    "    \"f1\": f1_score(y_test, yhat),\n",
    "}\n",
    "fair_before = fairness_metrics(y_test, yhat, prot_test)\n",
    "print(\"Metrics BEFORE:\", metrics_before)\n",
    "print(\"Fairness BEFORE:\", fair_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8992987",
   "metadata": {},
   "source": [
    "### TODO 4 — Mitigation\n",
    "Try a simple mitigation and justify the trade-offs in a Markdown cell:\n",
    "- **Option A:** Group-aware **thresholds** (choose threshold_A, threshold_B)\n",
    "- **Option B:** **Re-weighting** during training (class_weight or sample_weight)\n",
    "- **Option C:** Remove/retain `group` as feature; discuss proxy leakage and audits\n",
    "\n",
    "Re-compute metrics after mitigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Example mitigation: group-specific thresholds ===\n",
    "th_A, th_B = 0.50, 0.46  # <-- you may tune\n",
    "\n",
    "A = (prot_test==\"A\")\n",
    "B = (prot_test==\"B\")\n",
    "yhat_mitig = np.zeros_like(yhat)\n",
    "yhat_mitig[A] = (yhat_proba[A] >= th_A).astype(int)\n",
    "yhat_mitig[B] = (yhat_proba[B] >= th_B).astype(int)\n",
    "\n",
    "metrics_after = {\n",
    "    \"accuracy\": accuracy_score(y_test, yhat_mitig),\n",
    "    \"precision\": precision_score(y_test, yhat_mitig),\n",
    "    \"recall\": recall_score(y_test, yhat_mitig),\n",
    "    \"f1\": f1_score(y_test, yhat_mitig),\n",
    "}\n",
    "fair_after = fairness_metrics(y_test, yhat_mitig, prot_test)\n",
    "print(\"Metrics AFTER:\", metrics_after)\n",
    "print(\"Fairness AFTER:\", fair_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16da8f1",
   "metadata": {},
   "source": [
    "### TODO 5 — Explainability (Permutation Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(final_model, \"predict\"):\n",
    "    r = permutation_importance(final_model, X_test, y_test, scoring=\"f1\", n_repeats=5, random_state=RANDOM_SEED)\n",
    "    importances = pd.DataFrame({\"feature\": X_test.columns, \"importance\": r.importances_mean}).sort_values(\"importance\", ascending=False)\n",
    "    print(importances.head(10))\n",
    "else:\n",
    "    print(\"Permutation importance skipped (model lacks predict).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a36a26",
   "metadata": {},
   "source": [
    "### TODO 6 — Model Card (Markdown)\n",
    "Document: data sources (synthetic), intended use, metrics, fairness results, mitigation chosen,\n",
    "human-in-the-loop policy (manual review for borderline proba ∈ [0.45, 0.55]), and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Auto-Scoring Cell ===\n",
    "score = 0\n",
    "\n",
    "acc_pass = metrics_after[\"accuracy\"] >= 0.78\n",
    "f1_pass = metrics_after[\"f1\"] >= 0.78\n",
    "if acc_pass and f1_pass: score += 20\n",
    "\n",
    "eod_pass = abs(fair_after[\"equal_opportunity_diff\"]) <= 0.15\n",
    "if eod_pass: score += 20\n",
    "\n",
    "dp_pass = abs(fair_after[\"demographic_parity_diff\"]) <= 0.15\n",
    "if dp_pass: score += 20\n",
    "\n",
    "used_cv = True  # assume true if GridSearchCV above ran; feel free to toggle based on your pipeline\n",
    "used_importance = True  # assume permutation importance executed\n",
    "score += 20 if (used_cv and used_importance) else 0\n",
    "\n",
    "# Model card existence check (simple heuristic): look for a markdown cell with \"Model Card\" in nb text manually.\n",
    "model_card_claim = True  # set to True after you create it\n",
    "if model_card_claim: score += 20\n",
    "\n",
    "summary = {\n",
    "    \"accuracy_after\": metrics_after[\"accuracy\"],\n",
    "    \"f1_after\": metrics_after[\"f1\"],\n",
    "    \"equal_opportunity_diff_after\": fair_after[\"equal_opportunity_diff\"],\n",
    "    \"demographic_parity_diff_after\": fair_after[\"demographic_parity_diff\"],\n",
    "    \"score\": score,\n",
    "    \"criteria\": {\n",
    "        \"acc_f1\": (acc_pass and f1_pass),\n",
    "        \"eod<=0.15\": eod_pass,\n",
    "        \"dp<=0.15\": dp_pass,\n",
    "        \"cv+importance\": (used_cv and used_importance),\n",
    "        \"model_card\": model_card_claim\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"✅ Final Summary:\", summary)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
