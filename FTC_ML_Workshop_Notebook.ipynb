{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40cded0",
   "metadata": {},
   "source": [
    "\n",
    "# FTC ML Workshop: From Data to Model (with TFLite)\n",
    "\n",
    "This notebook is designed for **FTC teams** who want to understand **how Machine Learning works** instead of treating it as a black box. You'll:\n",
    "- Explore and analyze data\n",
    "- Train and evaluate models\n",
    "- Understand common pitfalls (overfitting, data imbalance, leakage)\n",
    "- Export a lightweight **TensorFlow Lite (TFLite)** model\n",
    "- See how this maps to **FTC workflows** (VisionPortal + TFOD / FTC-ML)\n",
    "\n",
    "> **Note**: FTC object recognition (boxes + labels) uses **object detection** models. Here, we start with **classification** (simpler) to build intuition, then show a **vision classifier** and **TFLite** conversion. You'll leave knowing the core ML process and how it translates to FTC workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69b0ca",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup\n",
    "Run the next cell to import the libraries we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tabular ML\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Vision ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# TFLite\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Versions:\")\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"pandas\", pd.__version__)\n",
    "import sklearn\n",
    "print(\"scikit-learn\", sklearn.__version__)\n",
    "print(\"tensorflow\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcaf62d",
   "metadata": {},
   "source": [
    "\n",
    "## 1) The ML Process (big picture)\n",
    "1. **Define the problem**: What are we predicting and why?\n",
    "2. **Collect data**: Images, sensor readings, etc.\n",
    "3. **Label data** (for supervised learning): human-labeled classes/boxes.\n",
    "4. **Split data**: Train vs. test (and sometimes validation).\n",
    "5. **Train** a model on the train split.\n",
    "6. **Evaluate** it on the test split using metrics appropriate for the task.\n",
    "7. **Iterate**: Improve data quality, features, architecture, and hyperparameters.\n",
    "8. **Export** a deployable artifact (e.g., `.tflite` for mobile/edge devices).\n",
    "9. **Deploy & monitor**: Run it on-robot/in-app; keep notes for traceability & ethics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5414be3",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Tabular Example (Iris dataset)\n",
    "A quick win to see the end-to-end pipeline on a small dataset built into scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "df = iris.frame.copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2957a2",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Explore the data\n",
    "Look at basic stats and relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b26368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f19dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick scatter plots (no specific colors set)\n",
    "plt.figure()\n",
    "plt.scatter(df['sepal length (cm)'], df['sepal width (cm)'])\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')\n",
    "plt.title('Sepal length vs width')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df['petal length (cm)'], df['petal width (cm)'])\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "plt.title('Petal length vs width')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691aa45",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 Train / test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[iris.feature_names].values\n",
    "y = df['target'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcd74d",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 Pipeline + model (Logistic Regression)\n",
    "Standard practice: **scale → model** inside a `Pipeline`. Then evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "y_pred = logreg_pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy (LogReg):\", acc)\n",
    "\n",
    "print(\"\\nClassification report (LogReg):\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix (LogReg)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4792d64",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4 Try a different model (Random Forest) + Cross-Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Test accuracy (RF):\", acc_rf)\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=iris.target_names)\n",
    "disp_rf.plot()\n",
    "plt.title(\"Confusion Matrix (Random Forest)\")\n",
    "plt.show()\n",
    "\n",
    "scores = cross_val_score(rf_pipeline, X, y, cv=5)\n",
    "print(\"5-fold CV accuracy (RF):\", scores, \"Mean:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0dbc2f",
   "metadata": {},
   "source": [
    "\n",
    "### 2.5 Takeaways (Tabular)\n",
    "- Start simple; compare a couple of models.\n",
    "- Use **train/test split** (and CV) to estimate generalization.\n",
    "- Inspect **confusion matrix** to see where the model struggles.\n",
    "- Document results for **traceability** (important for FTC ethics).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08ffac",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Vision Example (MNIST → TFLite)\n",
    "Now let's switch to a **vision classifier** to see the Keras → TFLite path used for mobile/edge deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395f6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load MNIST\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize and add channel axis\n",
    "mnist_x_train = mnist_x_train.astype(\"float32\") / 255.0\n",
    "mnist_x_test = mnist_x_test.astype(\"float32\") / 255.0\n",
    "mnist_x_train = np.expand_dims(mnist_x_train, -1)\n",
    "mnist_x_test = np.expand_dims(mnist_x_test, -1)\n",
    "\n",
    "print(\"Train:\", mnist_x_train.shape, \"Test:\", mnist_x_test.shape)\n",
    "\n",
    "# Build a small CNN\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(16, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(mnist_x_train, mnist_y_train, validation_split=0.1, epochs=3, batch_size=128, verbose=1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(mnist_x_test, mnist_y_test, verbose=0)\n",
    "print(\"MNIST test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9ddbd",
   "metadata": {},
   "source": [
    "\n",
    "### 3.1 Visualize predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Show a few predictions\n",
    "import random\n",
    "indices = random.sample(range(len(mnist_x_test)), 9)\n",
    "plt.figure()\n",
    "for i, idx in enumerate(indices, start=1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    plt.imshow(mnist_x_test[idx].squeeze(), cmap='gray')\n",
    "    pred = np.argmax(model.predict(mnist_x_test[idx:idx+1], verbose=0))\n",
    "    plt.title(f\"Pred: {pred} / True: {mnist_y_test[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44043136",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Convert Keras model to **TFLite**\n",
    "This mirrors how lightweight models are deployed on phones, Control Hubs, and embedded devices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b619cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "export_dir = Path('/mnt/data/ftc_ml_workshop')\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save Keras model\n",
    "keras_path = export_dir / 'mnist_cnn.h5'\n",
    "model.save(keras_path)\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_path = export_dir / 'mnist_cnn.tflite'\n",
    "with open(tflite_path, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Saved:\", keras_path, \"and\", tflite_path, \"Bytes:\", len(tflite_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b22b2",
   "metadata": {},
   "source": [
    "\n",
    "### 3.3 Run inference with the **TFLite Interpreter**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04349d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the TFLite interpreter to check that the model runs\n",
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_path))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Pick one sample\n",
    "sample = mnist_x_test[:1]\n",
    "interpreter.set_tensor(input_details[0]['index'], sample.astype(np.float32))\n",
    "interpreter.invoke()\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "pred = int(np.argmax(output))\n",
    "true = int(mnist_y_test[0])\n",
    "print(\"TFLite predicted:\", pred, \"| True:\", true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374a327",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Mapping to FTC Workflows\n",
    "- **Classification vs Object Detection**:  \n",
    "  - *Classification* → one label per image (this notebook).  \n",
    "  - *Object detection* → **bounding boxes + labels** (FTC TFOD).  \n",
    "- **FTC-ML Toolchain**: Collect videos/images of game elements → label boxes → cloud-train → download `.tflite` → load in **VisionPortal + TFOD** (OnBot Java / Android Studio).\n",
    "- **When to use which**:  \n",
    "  - Use **FTC-ML** for game objects detection (easiest, officially supported).  \n",
    "  - Use **custom training** (like Keras here) to learn concepts or build special-purpose models; convert to `.tflite` if deploying on device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca40f3d",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Ethics, Testing, and Traceability (DoD AI Principles, student-friendly)\n",
    "- **Responsible**: Use and share data appropriately; no identifying faces without consent.\n",
    "- **Equitable**: Avoid bias (e.g., only one lighting/background); diversify your data.\n",
    "- **Traceable**: Keep a short training log (dates, dataset versions, parameters, metrics).\n",
    "- **Reliable**: Test across conditions (lighting, angles, distance). Measure results.\n",
    "- **Governable**: Have a safe fallback (manual control) and a way to disable the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b190f80",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Challenge Ideas for Students\n",
    "- **Tabular**: Improve Iris accuracy using feature scaling, different models, or CV.\n",
    "- **Vision**: Add simple **data augmentation** to the MNIST model (flips/rotations). Measure the effect.\n",
    "- **Deployment**: Compare `.h5` vs `.tflite` file sizes; note the trade-offs.\n",
    "- **Reporting**: Create a 1-page summary with **accuracy**, **confusion matrix**, and **lessons learned**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ffd1da",
   "metadata": {},
   "source": [
    "\n",
    "### (Optional) Data augmentation for MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff075eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick augmentation example: slight rotations and shifts\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "aug_model = models.clone_model(model)\n",
    "aug_model.set_weights(model.get_weights())\n",
    "aug_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_aug = aug_model.fit(\n",
    "    datagen.flow(mnist_x_train, mnist_y_train, batch_size=128),\n",
    "    epochs=1,\n",
    "    steps_per_epoch=len(mnist_x_train)//128,\n",
    "    validation_data=(mnist_x_test, mnist_y_test),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss_aug, test_acc_aug = aug_model.evaluate(mnist_x_test, mnist_y_test, verbose=0)\n",
    "print(\"MNIST test accuracy after 1 epoch of augmentation:\", test_acc_aug)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
